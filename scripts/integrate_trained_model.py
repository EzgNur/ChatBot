"""
EÄŸitilmiÅŸ modeli chatbot sistemine entegre etme scripti
"""

import sys
import os
import json
import torch
from datetime import datetime
from typing import Dict, Any
import argparse

# Proje kÃ¶kÃ¼nÃ¼ PYTHONPATH'e ekle
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from backend.core.chatbot.bot import FreeChatBot


class TrainedModelIntegrator:
    def __init__(self, model_path: str = "./trained_rag_lora_model"):
        self.model_path = model_path
        self.base_model = None
        self.tokenizer = None
        self.trained_model = None
        self.rag_chatbot = None
        
    def load_trained_model(self):
        """EÄŸitilmiÅŸ modeli yÃ¼kle"""
        try:
            print("ğŸ”„ EÄŸitilmiÅŸ model yÃ¼kleniyor...")
            
            # Base model ve tokenizer yÃ¼kle
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.base_model = AutoModelForCausalLM.from_pretrained(
                "microsoft/DialoGPT-medium",
                torch_dtype=torch.float32,
                device_map="cpu"
            )
            
            # LoRA modeli yÃ¼kle
            self.trained_model = PeftModel.from_pretrained(
                self.base_model, 
                self.model_path
            )
            
            print("âœ… EÄŸitilmiÅŸ model yÃ¼klendi")
            return True
            
        except Exception as e:
            print(f"âŒ Model yÃ¼klenemedi: {e}")
            return False
    
    def load_rag_system(self):
        """RAG sistemini yÃ¼kle"""
        try:
            print("ğŸ”„ RAG sistemi yÃ¼kleniyor...")
            self.rag_chatbot = FreeChatBot()
            
            # Vectorstore'u yÃ¼kle
            vs_path = os.path.join(PROJECT_ROOT, "data", "vectorstore")
            if self.rag_chatbot.load_vectorstore(vs_path):
                print("âœ… RAG sistemi yÃ¼klendi")
                return True
            else:
                print("âŒ RAG sistemi yÃ¼klenemedi")
                return False
                
        except Exception as e:
            print(f"âŒ RAG sistemi yÃ¼klenemedi: {e}")
            return False
    
    def create_hybrid_chatbot(self):
        """Hibrit chatbot oluÅŸtur (RAG + EÄŸitilmiÅŸ Model)"""
        print("ğŸ”§ Hibrit chatbot oluÅŸturuluyor...")
        
        class HybridChatBot(FreeChatBot):
            def __init__(self, trained_model, tokenizer):
                super().__init__()
                self.trained_model = trained_model
                self.tokenizer = tokenizer
                self.use_trained_model = True
                
            def ask_hybrid(self, question: str) -> Dict:
                """Hibrit yanÄ±t Ã¼ret (RAG + EÄŸitilmiÅŸ Model)"""
                try:
                    # 1. RAG sistemi ile baÄŸlam al
                    rag_response = self.ask_groq(question)
                    rag_context = rag_response.get("answer", "")
                    
                    # 2. EÄŸitilmiÅŸ model ile yanÄ±t Ã¼ret
                    if self.use_trained_model:
                        # EÄŸitilmiÅŸ model iÃ§in input hazÄ±rla
                        context_prompt = f"BaÄŸlam: {rag_context}\nSoru: {question}\nYanÄ±t:"
                        
                        inputs = self.tokenizer.encode(
                            f"<|endoftext|>{context_prompt}<|endoftext|>",
                            return_tensors="pt"
                        )
                        
                        with torch.no_grad():
                            outputs = self.trained_model.generate(
                                inputs,
                                max_length=inputs.shape[1] + 150,
                                num_return_sequences=1,
                                temperature=0.7,
                                do_sample=True,
                                pad_token_id=self.tokenizer.eos_token_id
                            )
                        
                        trained_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                        
                        # EÄŸitilmiÅŸ model yanÄ±tÄ±nÄ± temizle
                        if "YanÄ±t:" in trained_response:
                            trained_response = trained_response.split("YanÄ±t:")[-1].strip()
                        
                        # Hibrit yanÄ±t oluÅŸtur
                        hybrid_answer = f"{trained_response}\n\n---\n\nğŸ“š Kaynak: {rag_response.get('sources', [])}"
                        
                        return {
                            "answer": hybrid_answer,
                            "sources": rag_response.get("sources", []),
                            "response_time": rag_response.get("response_time", "0s"),
                            "chunks_used": rag_response.get("chunks_used", 0),
                            "timestamp": datetime.now().isoformat(),
                            "model_type": "hybrid_rag_trained"
                        }
                    else:
                        # Sadece RAG kullan
                        return rag_response
                        
                except Exception as e:
                    print(f"âš ï¸ Hibrit yanÄ±t hatasÄ±: {e}")
                    # Fallback: sadece RAG
                    return rag_response
        
        # Hibrit chatbot oluÅŸtur
        hybrid_bot = HybridChatBot(self.trained_model, self.tokenizer)
        
        # RAG sistemini kopyala
        hybrid_bot.groq_client = self.rag_chatbot.groq_client
        hybrid_bot.vectorstore = self.rag_chatbot.vectorstore
        hybrid_bot.embeddings = self.rag_chatbot.embeddings
        
        print("âœ… Hibrit chatbot oluÅŸturuldu")
        return hybrid_bot
    
    def test_hybrid_system(self, test_questions: list = None):
        """Hibrit sistemi test et"""
        if not test_questions:
            test_questions = [
                "AB Mavi Kart iÃ§in 2025 maaÅŸ ÅŸartÄ± nedir?",
                "81A Ã¶n onay vizesi nedir?",
                "Anmeldung nedir ve neden Ã¶nemli?"
            ]
        
        print("ğŸ§ª Hibrit sistem testi baÅŸlÄ±yor...")
        
        # Hibrit chatbot oluÅŸtur
        hybrid_bot = self.create_hybrid_chatbot()
        
        results = []
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"Test {i}/{len(test_questions)}: {question}")
            
            try:
                response = hybrid_bot.ask_hybrid(question)
                print(f"âœ… Hibrit yanÄ±t: {response['answer'][:100]}...")
                results.append({
                    "question": question,
                    "response": response,
                    "success": True
                })
            except Exception as e:
                print(f"âŒ Test hatasÄ±: {e}")
                results.append({
                    "question": question,
                    "response": {"error": str(e)},
                    "success": False
                })
        
        # SonuÃ§larÄ± kaydet
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"hybrid_system_test_{timestamp}.json"
        output_path = os.path.join(PROJECT_ROOT, output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "test_info": {
                    "timestamp": timestamp,
                    "model_path": self.model_path,
                    "total_tests": len(test_questions)
                },
                "results": results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Hibrit test sonuÃ§larÄ± kaydedildi: {output_file}")
        
        # Ã–zet
        successful_tests = sum(1 for r in results if r["success"])
        print(f"\nğŸ“Š Hibrit Test Ã–zeti:")
        print(f"   Toplam test: {len(test_questions)}")
        print(f"   BaÅŸarÄ±lÄ± test: {successful_tests}")
        print(f"   BaÅŸarÄ± oranÄ±: {successful_tests/len(test_questions)*100:.1f}%")
        
        return results


def main():
    parser = argparse.ArgumentParser(description="EÄŸitilmiÅŸ model entegrasyonu")
    parser.add_argument("--model-path", type=str, default="./trained_rag_lora_model",
                        help="EÄŸitilmiÅŸ model yolu")
    parser.add_argument("--test", action="store_true",
                        help="Hibrit sistemi test et")
    
    args = parser.parse_args()
    
    integrator = TrainedModelIntegrator(args.model_path)
    
    # Modelleri yÃ¼kle
    if not integrator.load_trained_model():
        return
    
    if not integrator.load_rag_system():
        return
    
    # Hibrit sistemi test et
    if args.test:
        integrator.test_hybrid_system()
    
    print("\nğŸ¯ Entegrasyon tamamlandÄ±!")
    print("ğŸ’¡ Hibrit chatbot artÄ±k RAG + EÄŸitilmiÅŸ Model kullanÄ±yor")


if __name__ == "__main__":
    main()
