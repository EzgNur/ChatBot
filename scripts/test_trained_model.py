"""
EÄŸitilmiÅŸ RAG + LoRA modelini test etme scripti
"""

import sys
import os
import json
import torch
from datetime import datetime
from typing import List, Dict, Any
import argparse

# Proje kÃ¶kÃ¼nÃ¼ PYTHONPATH'e ekle
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from backend.core.chatbot.bot import FreeChatBot


class TrainedModelTester:
    def __init__(self, model_path: str = "./trained_rag_lora_model"):
        self.model_path = model_path
        self.base_model = None
        self.tokenizer = None
        self.trained_model = None
        self.rag_chatbot = None
        
    def load_trained_model(self):
        """EÄŸitilmiÅŸ modeli yÃ¼kle"""
        try:
            print("ğŸ”„ EÄŸitilmiÅŸ model yÃ¼kleniyor...")
            
            # Base model ve tokenizer yÃ¼kle
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            self.base_model = AutoModelForCausalLM.from_pretrained(
                "microsoft/DialoGPT-medium",
                torch_dtype=torch.float32,  # CPU iÃ§in float32
                device_map="cpu"  # CPU kullan
            )
            
            # LoRA modeli yÃ¼kle
            self.trained_model = PeftModel.from_pretrained(
                self.base_model, 
                self.model_path
            )
            
            print("âœ… EÄŸitilmiÅŸ model yÃ¼klendi")
            return True
            
        except Exception as e:
            print(f"âŒ Model yÃ¼klenemedi: {e}")
            return False
    
    def load_rag_system(self):
        """RAG sistemini yÃ¼kle"""
        try:
            print("ğŸ”„ RAG sistemi yÃ¼kleniyor...")
            self.rag_chatbot = FreeChatBot()
            
            # Vectorstore'u yÃ¼kle
            vs_path = os.path.join(PROJECT_ROOT, "data", "vectorstore")
            if self.rag_chatbot.load_vectorstore(vs_path):
                print("âœ… RAG sistemi yÃ¼klendi")
                return True
            else:
                print("âŒ RAG sistemi yÃ¼klenemedi")
                return False
                
        except Exception as e:
            print(f"âŒ RAG sistemi yÃ¼klenemedi: {e}")
            return False
    
    def test_single_question(self, question: str) -> Dict:
        """Tek bir soruyu test et"""
        print(f"\nğŸ” Test sorusu: {question}")
        
        results = {
            "question": question,
            "trained_model_response": "",
            "rag_response": "",
            "comparison": {}
        }
        
        # 1. EÄŸitilmiÅŸ model testi
        try:
            print("ğŸ¤– EÄŸitilmiÅŸ model testi...")
            inputs = self.tokenizer.encode(
                f"<|endoftext|>{question}<|endoftext|>",
                return_tensors="pt"
            )
            
            with torch.no_grad():
                outputs = self.trained_model.generate(
                    inputs,
                    max_length=inputs.shape[1] + 100,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            trained_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            results["trained_model_response"] = trained_response
            print(f"âœ… EÄŸitilmiÅŸ model yanÄ±tÄ±: {trained_response[:100]}...")
            
        except Exception as e:
            print(f"âŒ EÄŸitilmiÅŸ model hatasÄ±: {e}")
            results["trained_model_response"] = f"Hata: {str(e)}"
        
        # 2. RAG sistemi testi
        try:
            print("ğŸ” RAG sistemi testi...")
            rag_response = self.rag_chatbot.ask_groq(question)
            results["rag_response"] = rag_response.get("answer", str(rag_response))
            print(f"âœ… RAG yanÄ±tÄ±: {results['rag_response'][:100]}...")
            
        except Exception as e:
            print(f"âŒ RAG sistemi hatasÄ±: {e}")
            results["rag_response"] = f"Hata: {str(e)}"
        
        # 3. KarÅŸÄ±laÅŸtÄ±rma
        results["comparison"] = {
            "trained_model_length": len(results["trained_model_response"]),
            "rag_length": len(results["rag_response"]),
            "both_working": "Hata" not in results["trained_model_response"] and "Hata" not in results["rag_response"]
        }
        
        return results
    
    def run_comprehensive_test(self, test_questions: List[str] = None):
        """KapsamlÄ± test Ã§alÄ±ÅŸtÄ±r"""
        if not test_questions:
            test_questions = [
                "AB Mavi Kart iÃ§in 2025 maaÅŸ ÅŸartÄ± nedir?",
                "81A Ã¶n onay vizesi nedir?",
                "Anmeldung nedir ve neden Ã¶nemli?",
                "Almanya'da Ã§alÄ±ÅŸma izni nasÄ±l alÄ±nÄ±r?",
                "Mavi Kart baÅŸvuru sÃ¼reci nasÄ±l iÅŸler?"
            ]
        
        print("ğŸš€ KapsamlÄ± test baÅŸlÄ±yor...")
        
        # Modelleri yÃ¼kle
        if not self.load_trained_model():
            return
        
        if not self.load_rag_system():
            return
        
        # Testleri Ã§alÄ±ÅŸtÄ±r
        results = []
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*60}")
            print(f"Test {i}/{len(test_questions)}")
            result = self.test_single_question(question)
            results.append(result)
        
        # SonuÃ§larÄ± kaydet
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"trained_model_test_results_{timestamp}.json"
        output_path = os.path.join(PROJECT_ROOT, output_file)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "test_info": {
                    "timestamp": timestamp,
                    "model_path": self.model_path,
                    "total_tests": len(test_questions)
                },
                "results": results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Test sonuÃ§larÄ± kaydedildi: {output_file}")
        
        # Ã–zet
        working_tests = sum(1 for r in results if r["comparison"]["both_working"])
        print(f"\nğŸ“Š Test Ã–zeti:")
        print(f"   Toplam test: {len(test_questions)}")
        print(f"   BaÅŸarÄ±lÄ± test: {working_tests}")
        print(f"   BaÅŸarÄ± oranÄ±: {working_tests/len(test_questions)*100:.1f}%")
        
        return results


def main():
    parser = argparse.ArgumentParser(description="EÄŸitilmiÅŸ model testi")
    parser.add_argument("--model-path", type=str, default="./trained_rag_lora_model",
                        help="EÄŸitilmiÅŸ model yolu")
    parser.add_argument("--questions", type=str, nargs="+", default=None,
                        help="Test sorularÄ±")
    
    args = parser.parse_args()
    
    tester = TrainedModelTester(args.model_path)
    tester.run_comprehensive_test(args.questions)


if __name__ == "__main__":
    main()
