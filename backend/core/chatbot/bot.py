"""
Optimize edilmiÅŸ LangChain RetrievalQA chatbot modÃ¼lÃ¼
Oktay Ã–zdemir blog verileri ile eÄŸitilmiÅŸ - GROQ ve ChatGPT API desteÄŸi
"""

import os
from typing import Optional, Dict, List
import unicodedata
from datetime import datetime
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.retrievers import BM25Retriever
from langchain.prompts import PromptTemplate
from langchain_community.llms import LlamaCpp
from sentence_transformers import CrossEncoder
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    print("âš ï¸ GROQ paketi yÃ¼klÃ¼ deÄŸil: pip install groq")

try:
    import torch
    from transformers import AutoTokenizer, AutoModelForCausalLM
    from peft import PeftModel
    TRAINED_MODEL_AVAILABLE = True
except ImportError:
    TRAINED_MODEL_AVAILABLE = False
    print("âš ï¸ EÄŸitilmiÅŸ model paketleri yÃ¼klÃ¼ deÄŸil: pip install torch transformers peft")

class OptimizedChatBot:
    def __init__(self, openai_api_key: Optional[str] = None, model_name: str = "gpt-4o-mini"):
        """
        Optimize edilmiÅŸ chatbot sÄ±nÄ±fÄ± - Maliyet etkin ChatGPT kullanÄ±mÄ±
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("âš ï¸ OpenAI API anahtarÄ± gerekli! OPENAI_API_KEY environment variable'Ä±nÄ± ayarlayÄ±n.")
        
        self.model_name = model_name  # gpt-4o-mini daha uygun maliyetli
        print(f"ğŸ¤– ChatGPT modeli: {model_name}")
        
        # AynÄ± embedding modeli (tutarlÄ±lÄ±k iÃ§in kritik!)
        print("ğŸ”„ Embedding modeli yÃ¼kleniyor...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        print("âœ… Embedding modeli hazÄ±r")
        
        self.vectorstore = None
        self.qa_chain = None
        
        # Optimize edilmiÅŸ TÃ¼rkÃ§e prompt template
        self.prompt_template = """Sen Oktay Ã–zdemir'in blog yazÄ±larÄ±ndan eÄŸitilmiÅŸ bir hukuk ve gÃ¶Ã§ uzmanÄ± asistanÄ±sÄ±n.

AÅŸaÄŸÄ±daki baÄŸlamsal bilgileri kullanarak soruyu TÃ¼rkÃ§e olarak profesyonel bir ÅŸekilde cevapla:

BAÄLAMSAL BÄ°LGÄ°LER:
{context}

SORU: {question}

CEVAPLAMA KURALLARI:
1. Sadece verilen baÄŸlamsal bilgileri kullan
2. Bilgi yoksa "Bu konuda elimdeki kaynaklarda yeterli bilgi bulunmuyor" de
3. MÃ¼mkÃ¼nse kaynak blog yazÄ±sÄ±nÄ±n baÅŸlÄ±ÄŸÄ±nÄ± belirt
4. Hukuki konularda dikkatli ol, genel bilgi ver
5. TÃ¼rkÃ§e ve anlaÅŸÄ±lÄ±r bir dil kullan

CEVAP:"""

class FreeChatBot:
    def __init__(self, groq_api_key: Optional[str] = None, model_name: str = "llama-3.3-70b-versatile"):
        """
        ÃœCRETSIZ GROQ destekli chatbot sÄ±nÄ±fÄ±
        """
        self.groq_api_key = groq_api_key or os.getenv("GROQ_API_KEY")
        if not self.groq_api_key and GROQ_AVAILABLE:
            print("âš ï¸ GROQ API anahtarÄ± yok. Ãœcretsiz hesap: console.groq.com")
        
        self.model_name = model_name
        print(f"ğŸ†“ GROQ modeli: {model_name}")
        
        # AynÄ± embedding modeli (tutarlÄ±lÄ±k iÃ§in kritik!)
        print("ğŸ”„ Embedding modeli yÃ¼kleniyor...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        print("âœ… Embedding modeli hazÄ±r")
        
        self.vectorstore = None
        self.groq_client = None
        self._bm25_retriever = None
        
        # EÄŸitilmiÅŸ model desteÄŸi
        self.trained_model = None
        self.trained_tokenizer = None
        self.use_trained_model = False
        
        if self.groq_api_key and GROQ_AVAILABLE:
            self.groq_client = Groq(api_key=self.groq_api_key)
            print("âœ… GROQ istemcisi hazÄ±r")
        
        # GROQ iÃ§in TÃ¼rkÃ§e sistem promptu (tam cÃ¼mleler, imla ve noktalama odaklÄ±)
        self.prompt_template = """Sen Oktay Ã–zdemir'in blog yazÄ±larÄ±ndan eÄŸitilmiÅŸ bir hukuk ve gÃ¶Ã§ uzmanÄ± asistansÄ±n.

AÅŸaÄŸÄ±daki BAÄLAM'a dayanarak soruyu TÃ¼rkÃ§e ve orta uzunlukta (yaklaÅŸÄ±k 8â€“12 cÃ¼mle) net bir dille yanÄ±tla.

YAZIM VE BÄ°Ã‡EM KURALLARI:
- YazÄ±m ve noktalama kurallarÄ±na tam uy; gereksiz tekrar ve dolgu cÃ¼mlesi kullanma.
- Rakamlar, mevzuat kodlarÄ± (Ã¶r. 18a/18b/81a) ve â‚¬ tutarlarÄ±nÄ± aynen koru.
- GerektiÄŸinde 5-7 maddelik kÄ±sa bir bÃ¶lÃ¼m ekle (Ã¶r. "Åartlar:"), diÄŸer yerlerde madde kullanma.
- BaÄŸlama dayanmayan bilgi ekleme; emin deÄŸilsen "Bu konuda elimdeki kaynaklarda yeterli bilgi bulunmuyor" de.

Ã–NEMLÄ°: Her cÃ¼mleyi tamamla. YarÄ±da kalan cÃ¼mleler yazma. Her paragrafÄ± ve maddeyi noktalama iÅŸareti ile bitir.

BAÄLAM:
{context}

SORU: {question}

        KURALLAR:
- Sadece baÄŸlamdaki bilgileri kullan; link veya kaynak listesi verme.
- CÃ¼mleleri kÄ±sa ve aÃ§Ä±k yaz; tutarlÄ± terimler kullan.
- YanÄ±tÄ± doÄŸal bir giriÅŸle baÅŸlat; gerekiyorsa maddelerden sonra kÄ±sa bir kapanÄ±ÅŸ cÃ¼mlesi ekle.
        - Her cÃ¼mleyi tamamla, yarÄ±da bÄ±rakma.
        - Almanca terimleri ilk geÃ§tiÄŸi yerde parantez iÃ§inde TÃ¼rkÃ§esi ile birlikte yaz. Ã–rnek: "Aufenthaltstitel (ikamet izni)", "Niederlassungserlaubnis (yerleÅŸim izni)", "Anmeldung (adres kaydÄ±)". Sonraki tekrarlarÄ±nda kÄ±sa hÃ¢li yeterlidir.

CEVAP:"""

    def expand_query(self, question: str) -> str:
        """
        Soru geniÅŸletme: eÅŸanlam/terim varyantlarÄ± ve sayÄ±/yasa kodu normalizasyonu ile
        arama kapsamasÄ±nÄ± artÄ±rÄ±r; Ã¶zgÃ¼n terimleri korur.
        """
        q = question or ""
        ql = q.lower()
        expansions: List[str] = []

        def add(t: str) -> None:
            if t and t not in expansions:
                expansions.append(t)

        # Terim eÅŸanlamlarÄ± / varyantlarÄ± - GENÄ°ÅLETÄ°LMÄ°Å
        if any(k in ql for k in ["anmeldung", "adres", "ikamet kaydÄ±", "adres kaydÄ±"]):
            add("Anmeldung adres kaydÄ± ikamet kaydÄ± WohnungsgeberbestÃ¤tigung 14 gÃ¼n")
        if any(k in ql for k in ["mavi kart", "blue card", "ab mavi"]):
            add("AB Mavi Kart Blue Card bottleneck nitelikli iÅŸ gÃ¼cÃ¼ aÃ§Ä±ÄŸÄ± 48.300 43.759,80")
        if any(k in ql for k in ["fÄ±rsat kart", "chancenkarte"]):
            add("Chancenkarte fÄ±rsat kartÄ± Â§20a puan sistemi mesleki yeterlilik")
        if any(k in ql for k in ["81a", "Ã¶n onay", "hÄ±zlandÄ±rÄ±lmÄ±ÅŸ"]):
            add("Â§81a hÄ±zlandÄ±rÄ±lmÄ±ÅŸ Ã¶n onay iÅŸ ajansÄ± yabancÄ±lar dairesi Ä°kamet YasasÄ±")
        if any(k in ql for k in ["18a", "18b", "18g"]):
            add("Â§18a Â§18b Â§18g Ä°kamet YasasÄ± nitelikli istihdam")
        if any(k in ql for k in ["oturum", "yerleÅŸim", "niederlassung"]):
            add("oturum izni ikamet izni kalÄ±cÄ± oturum Niederlassungserlaubnis B1 36 ay emeklilik sigortasÄ±")
        if any(k in ql for k in ["maaÅŸ", "euro", "brÃ¼t", "kazanÃ§"]):
            add("brÃ¼t maaÅŸ â‚¬ euro yÄ±llÄ±k aylÄ±k eÅŸik asgari bottleneck 53.130 45 yaÅŸ")
        if any(k in ql for k in ["sÃ¼rÃ¼cÃ¼", "src", "ehliyet"]):
            add("profesyonel sÃ¼rÃ¼cÃ¼ SRC psikoteknik ehliyet sÄ±nÄ±fÄ±")
        if any(k in ql for k in ["niteliksiz", "kalÄ±cÄ± ikamet"]):
            add("niteliksiz iÅŸÃ§i kalÄ±cÄ± ikamet A2 sosyal gÃ¼venlik Ã§alÄ±ÅŸma izni")
        if any(k in ql for k in ["meslek", "Ã§alÄ±ÅŸmak", "iÅŸ", "Ã¶n lisans", "mezun"]):
            add("meslek iÅŸ Ã§alÄ±ÅŸma Ã¶n lisans mezun nitelikli istihdam Ã§alÄ±ÅŸma izni")

        # SayÄ±larÄ± biÃ§im varyantlarÄ±yla ekle (4.427,50 â†” 4427.50 â†” 442750)
        import re
        nums = re.findall(r"\d+[\.,]?\d*", q)
        for n in nums:
            add(n)
            add(n.replace(".", "").replace(",", "."))
            add(n.replace(",", ""))

        # Yasa sembolleri normalize
        if "Â§" in q:
            add(q.replace("Â§", ""))

        return q + ("\n" + " ".join(expansions) if expansions else "")

    def load_vectorstore(self, vectorstore_path: str = None):
        """
        Vector store'u yÃ¼kle (GROQ iÃ§in)
        """
        if not vectorstore_path:
            # Proje kÃ¶kÃ¼nÃ¼n altÄ±ndaki data/vectorstore'u kullan
            vectorstore_path = os.path.join(
                os.path.dirname(__file__), "..", "..", "..", "data", "vectorstore"
            )
        
        try:
            print(f"ğŸ“‚ Vector store yÃ¼kleniyor: {vectorstore_path}")
            self.vectorstore = FAISS.load_local(
                vectorstore_path, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            
            doc_count = self.vectorstore.index.ntotal
            print(f"âœ… Vector store yÃ¼klendi: {doc_count} chunk hazÄ±r")
            return True
            
        except Exception as e:
            print(f"âŒ Vector store yÃ¼klenirken hata: {e}")
            return False

    def get_category_menu(self) -> Dict:
        """
        Ana baÅŸlÄ±k kategorilerini dÃ¶ndÃ¼r
        """
        return {
            "special_response": True,
            "type": "category_menu",
            "answer": "Hangi konuda yardÄ±m almak istiyorsunuz? LÃ¼tfen aÅŸaÄŸÄ±daki kategorilerden birini seÃ§in:",
            "categories": [
                {
                    "id": "hukuk_goc",
                    "title": "ğŸ›ï¸ HUKUK VE GÃ–Ã‡ HUKUKU",
                    "description": "Vize tÃ¼rleri, ikamet izinleri, yasal dayanaklar, iltica sÃ¼reÃ§leri"
                },
                {
                    "id": "mesleki_egitim",
                    "title": "ğŸ‘¨â€ğŸ’¼ MESLEKÄ° EÄÄ°TÄ°M VE NÄ°TELÄ°KLER", 
                    "description": "EÄŸitim tÃ¼rleri, denklik iÅŸlemleri, mesleki yeterlilik, belge tÃ¼rleri"
                },
                {
                    "id": "is_calisma",
                    "title": "ğŸ’¼ Ä°Å VE Ã‡ALIÅMA HAYATI",
                    "description": "Meslek gruplarÄ±, iÅŸ sÃ¶zleÅŸmeleri, iÅŸ ajansÄ±, Ã§alÄ±ÅŸma izinleri"
                },
                {
                    "id": "yerlesim_yasam",
                    "title": "ğŸ  YERLEÅÄ°M VE YAÅAM",
                    "description": "Adres kaydÄ±, dil gereksinimleri, sosyal gÃ¼venlik, kalÄ±cÄ± ikamet"
                },
                {
                    "id": "mali_konular",
                    "title": "ğŸ’° MALÄ° KONULAR",
                    "description": "MaaÅŸ ÅŸartlarÄ±, harÃ§lar, denklik masraflarÄ±, tercÃ¼me"
                },
                {
                    "id": "ulke_bazli",
                    "title": "ğŸŒ ÃœLKE BAZLI BÄ°LGÄ°LER",
                    "description": "Almanya, Ä°ngiltere, diÄŸer AB Ã¼lkeleri"
                },
                {
                    "id": "surec_prosedur",
                    "title": "ğŸ“‹ SÃœREÃ‡ VE PROSEDÃœRLER",
                    "description": "BaÅŸvuru sÃ¼reÃ§leri, belge hazÄ±rlama, onay sÃ¼reÃ§leri, sÃ¼reler"
                },
                {
                    "id": "ozel_durumlar",
                    "title": "ğŸ¯ Ã–ZEL DURUMLAR",
                    "description": "YaÅŸ faktÃ¶rÃ¼, meslek Ã¶zelinde, dil seviyeleri, eÄŸitim sÃ¼releri"
                }
            ],
            "action_buttons": [
                {
                    "text": "âŒ Kategori seÃ§meden devam et",
                    "type": "skip_categories"
                }
            ]
        }

    def get_category_keywords(self, category_id: str) -> List[str]:
        """
        Kategori ID'sine gÃ¶re ilgili anahtar kelimeleri dÃ¶ndÃ¼r
        """
        category_keywords = {
            "hukuk_goc": [
                "mavi kart", "blue card", "81a", "Ã¶n onay", "fÄ±rsat kartÄ±", "chancenkarte",
                "niederlassungserlaubnis", "Ã§alÄ±ÅŸma izni", "ikamet izni", "18a", "18b", "18g", "19c", "20a",
                "iltica", "sÄ±ÄŸÄ±nma", "mÃ¼lteci", "bottleneck", "nitelikli iÅŸ gÃ¼cÃ¼"
            ],
            "mesleki_egitim": [
                "Ã¶n lisans", "meslek lisesi", "kalfalÄ±k", "Ã§Ä±raklÄ±k", "ustalÄ±k", "16. madde",
                "ihk", "hwk", "bezirksregierung", "denklik", "tam denklik", "kÄ±smi denklik",
                "denklik tamamlama", "myk", "mesleki yeterlilik", "ausbildung"
            ],
            "is_calisma": [
                "tÄ±r ÅŸofÃ¶rÃ¼", "inÅŸaat ustasÄ±", "kasap", "aÅŸÃ§Ä±", "elektrikÃ§i", "oto tamir",
                "depo Ã§alÄ±ÅŸanÄ±", "nitelikli iÅŸ sÃ¶zleÅŸmesi", "maaÅŸ ÅŸartÄ±", "agentur fÃ¼r arbeit",
                "Ã§alÄ±ÅŸma vizesi", "oturum izni", "iÅŸ sÃ¶zleÅŸmesi"
            ],
            "yerlesim_yasam": [
                "anmeldung", "wohnungsgeberbestÃ¤tigung", "adres kaydÄ±", "a2", "b1", "c1",
                "emeklilik sigortasÄ±", "sosyal gÃ¼venlik", "kalÄ±cÄ± ikamet", "36 ay", "dil seviyesi"
            ],
            "mali_konular": [
                "48.300", "43.759,80", "53.130", "45 yaÅŸ", "harÃ§", "vize harcÄ±", "oturum kartÄ±",
                "denklik masrafÄ±", "tercÃ¼me", "411â‚¬", "500-600â‚¬", "brÃ¼t maaÅŸ", "euro"
            ],
            "ulke_bazli": [
                "almanya", "ingiltere", "scale-up", "ankara anlaÅŸmasÄ±", "avrupa birliÄŸi",
                "ikamet yasasÄ±", "birleÅŸik krallÄ±k", "ab Ã¼lkeleri"
            ],
            "surec_prosedur": [
                "baÅŸvuru sÃ¼reci", "denklik baÅŸvurusu", "evrak toplama", "tercÃ¼me",
                "yabancÄ±lar dairesi", "iÅŸ ajansÄ±", "7-8 ay", "8 hafta", "vize sÃ¼reci"
            ],
            "ozel_durumlar": [
                "45 yaÅŸ", "profesyonel sÃ¼rÃ¼cÃ¼", "niteliksiz iÅŸÃ§i", "dil seviyesi",
                "eÄŸitim sÃ¼resi", "2 yÄ±l", "yaÅŸ faktÃ¶rÃ¼", "meslek Ã¶zelinde"
            ]
        }
        return category_keywords.get(category_id, [])

    def check_special_keywords(self, question: str) -> Dict:
        """
        Ã–zel kelimeleri kontrol et ve uygun yÃ¶nlendirme yap
        """
        # TÃ¼rkÃ§e karakterleri normalize ederek daha saÄŸlam anahtar-kelime tespiti
        def normalize(text: str) -> str:
            text = text.lower()
            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')
            return text

        # EÄŸer soru, backend'de detay modu iÃ§in geniÅŸletilmiÅŸ ÅŸablonu iÃ§eriyorsa,
        # niyet tespitini sadece "Yeni talep:" bÃ¶lÃ¼mÃ¼ne gÃ¶re yapalÄ±m
        if "Yeni talep:" in question:
            try:
                question = question.split("Yeni talep:", 1)[1].strip()
            except Exception:
                pass

        question_lower = question.lower()
        question_norm = normalize(question)

        # Kategori seÃ§imi kontrolÃ¼
        if any(p in question_lower for p in ["kategori", "baÅŸlÄ±k", "konu", "hangi", "yardÄ±m", "nasÄ±l"]):
            return self.get_category_menu()
        
        # Kategori ID'si kontrolÃ¼ (kullanÄ±cÄ± kategori seÃ§tiyse)
        category_indicators = {
            "hukuk_goc": ["hukuk", "gÃ¶Ã§", "vize", "ikamet", "iltica"],
            "mesleki_egitim": ["meslek", "eÄŸitim", "denklik", "kalfalÄ±k", "ustalÄ±k"],
            "is_calisma": ["iÅŸ", "Ã§alÄ±ÅŸma", "meslek", "ÅŸofÃ¶r", "usta", "kasap"],
            "yerlesim_yasam": ["yerleÅŸim", "yaÅŸam", "anmeldung", "dil", "a2", "b1"],
            "mali_konular": ["maaÅŸ", "harÃ§", "mali", "euro", "Ã¼cret", "masraf"],
            "ulke_bazli": ["almanya", "ingiltere", "Ã¼lke", "scale-up"],
            "surec_prosedur": ["sÃ¼reÃ§", "prosedÃ¼r", "baÅŸvuru", "evrak", "sÃ¼re"],
            "ozel_durumlar": ["yaÅŸ", "Ã¶zel", "durum", "faktÃ¶r", "seviye"]
        }
        
        selected_category = None
        for category_id, indicators in category_indicators.items():
            if any(indicator in question_lower for indicator in indicators):
                selected_category = category_id
                break
        
        # Sadece detay istemi ise Ã¶zel yÃ¶nlendirme tetikleme (danÄ±ÅŸman/eligibility) yapma
        detail_only = any(p in question_lower for p in [
            "detay", "ayrÄ±ntÄ±", "daha fazla bilgi", "detaylandÄ±r", "uzat"
        ])
        if detail_only:
            return {"special_response": False}
        
        # Ä°ltica kelimesi tespit edilirse
        if (
            any(word in question_lower for word in ["iltica", "sÄ±ÄŸÄ±nma", "mÃ¼lteci", "sÄ±ÄŸÄ±nma talebi"]) or
            any(word in question_norm for word in ["iltica", "sigunma", "multeci", "sigunma talebi"])
        ):
            return {
                "special_response": True,
                "type": "iltica",
                "answer": "Ä°ltica konusunda size yardÄ±mcÄ± olabilirim. AÅŸaÄŸÄ±daki gÃ¼ncel haberler ve bilgiler size faydalÄ± olabilir:",
                "sources": [
                    {
                        "title": "Almanya'ya 2015'de gelen mÃ¼ltecilerin %64'Ã¼ iÅŸ hayatÄ±na katÄ±ldÄ±",
                        "url": "https://oktayozdemir.com.tr/blog/2015de-gelen-multecilerin-is-hayatinda/",
                        "description": "Son araÅŸtÄ±rma sonuÃ§larÄ± ve entegrasyon baÅŸarÄ±sÄ± hakkÄ±nda detaylÄ± bilgi"
                    }
                ],
                "action_buttons": [
                    {
                        "text": "ğŸ“‹ Ä°ltica BaÅŸvuru Formu",
                        "url": "https://oktayozdemir.com.tr/basvuru-formu/",
                        "type": "form"
                    },
                    {
                        "text": "ğŸ“ Ä°ltica DanÄ±ÅŸmanÄ±",
                        "url": f"https://wa.me/{os.getenv('WHATSAPP_PHONE','4920393318883')}?text=Ä°ltica%20konusunda%20danÄ±ÅŸmanlÄ±k%20istiyorum",
                        "type": "whatsapp"
                    }
                ]
            }
        
        # DanÄ±ÅŸman talebi tespit edilirse
        if (any(word in question_lower for word in ["danÄ±ÅŸman", "danÄ±ÅŸmana baÄŸlanmak", "danÄ±ÅŸmana", "whatsapp", "iletiÅŸime geÃ§", "baÄŸla", "baÄŸlan"]) or
            any(word in question_norm for word in ["danisman", "danismana baglanmak", "danismana", "whatsapp", "iletisime gec", "bagla", "baglan"])):
            return {
                "special_response": True,
                "type": "consultant",
                "answer": "Elbette, daha detaylÄ± bilgi iÃ§in sizi danÄ±ÅŸmanÄ±mÄ±za yÃ¶nlendiriyorum. HoÅŸÃ§a kalÄ±n!",
                "sources": [],
                "action_buttons": [
                    {
                        "text": "ğŸ“ BaÅŸvuru DanÄ±ÅŸmanÄ±",
                        "url": f"https://wa.me/{os.getenv('WHATSAPP_PHONE','4920393318883')}?text=DanÄ±ÅŸmanlÄ±k%20talep%20ediyorum",
                        "type": "whatsapp"
                    }
                ]
            }
        
        # BaÅŸvuru/gÃ¶Ã§/uygunluk kelimeleri tespit edilirse (form Ã¶ner)
        if any(word in question_lower for word in [
            "baÅŸvuru", "gÃ¶Ã§", "uygun", "uygunluk", "uygun mu", "baÅŸvuru yapmak", "baÅŸvuru yapmak istiyorum"
        ]):
            return {
                "special_response": True,
                "type": "eligibility",
                "answer": "KÄ±sa bir uygunluk kontrolÃ¼ yapalÄ±m. AÅŸaÄŸÄ±daki formu aÃ§arak baÅŸlayabilirsiniz.",
                "sources": [],
                "action_buttons": [
                    {
                        "text": "âœ… Uygunluk DeÄŸerlendirme Formu",
                        "url": "https://oktayozdemir.com.tr/basvuru-formu/",
                        "type": "form"
                    },
                    {
                        "text": "ğŸ“ BaÅŸvuru DanÄ±ÅŸmanÄ±",
                        "url": f"https://wa.me/{os.getenv('WHATSAPP_PHONE','4920393318883')}?text=GÃ¶Ã§%20baÅŸvurusu%20konusunda%20danÄ±ÅŸmanlÄ±k%20istiyorum",
                        "type": "whatsapp"
                    }
                ]
            }
        
        return {"special_response": False}

    def load_trained_model(self, model_path: str = "./trained_rag_lora_model") -> bool:
        """EÄŸitilmiÅŸ modeli yÃ¼kle"""
        if not TRAINED_MODEL_AVAILABLE:
            print("âš ï¸ EÄŸitilmiÅŸ model paketleri yÃ¼klÃ¼ deÄŸil")
            return False
        
        try:
            print("ğŸ”„ EÄŸitilmiÅŸ model yÃ¼kleniyor...")
            
            # Tokenizer yÃ¼kle
            self.trained_tokenizer = AutoTokenizer.from_pretrained(model_path)
            
            # Base model yÃ¼kle
            base_model = AutoModelForCausalLM.from_pretrained(
                "microsoft/DialoGPT-medium",
                torch_dtype=torch.float32,
                device_map="cpu"
            )
            
            # LoRA modeli yÃ¼kle
            self.trained_model = PeftModel.from_pretrained(base_model, model_path)
            
            self.use_trained_model = True
            print("âœ… EÄŸitilmiÅŸ model yÃ¼klendi")
            return True
            
        except Exception as e:
            print(f"âŒ EÄŸitilmiÅŸ model yÃ¼klenemedi: {e}")
            return False

    def hybrid_search(self, question: str, k_chunks: int = 10) -> List:
        """
        Hibrit arama: BM25 + Semantic similarity
        """
        try:
            # 1. Semantic similarity search
            semantic_results = self.vectorstore.similarity_search(question, k=k_chunks)
            
            # 2. BM25 search (eÄŸer mevcut ise)
            bm25_results = []
            try:
                # BM25 arama iÃ§in alternatif yÃ¶ntem
                bm25_results = self.vectorstore.similarity_search_with_score(question, k=k_chunks)
                bm25_results = [doc for doc, score in bm25_results if score > 0.7]  # YÃ¼ksek skorlu sonuÃ§lar
            except:
                pass  # BM25 mevcut deÄŸilse sadece semantic kullan
            
            # 3. SonuÃ§larÄ± birleÅŸtir ve tekrarlarÄ± kaldÄ±r
            all_results = semantic_results + bm25_results
            unique_results = []
            seen_content = set()
            
            for doc in all_results:
                if doc.page_content not in seen_content:
                    unique_results.append(doc)
                    seen_content.add(doc.page_content)
            
            return unique_results[:k_chunks]
            
        except Exception as e:
            print(f"âš ï¸ Hibrit arama hatasÄ±: {e}")
            # Fallback: sadece semantic search
            return self.vectorstore.similarity_search(question, k=k_chunks)

    def ask_groq(self, question: str, k_chunks: int = 10, selected_category: str = None) -> Dict:  # Optimize edilmiÅŸ
        """
        GROQ API ile soru sor - kategori odaklÄ± arama desteÄŸi
        """
        if not self.groq_client:
            return {
                "answer": "GROQ API anahtarÄ± gerekli. console.groq.com adresinden Ã¼cretsiz alabilirsiniz.",
                "sources": [],
                "response_time": "0s",
                "chunks_used": 0,
                "timestamp": datetime.now().isoformat()
            }
        
        if not self.vectorstore:
            return {
                "answer": "Vector store yÃ¼klenmemiÅŸ. Ã–nce load_vectorstore() Ã§alÄ±ÅŸtÄ±rÄ±n.",
                "sources": [],
                "response_time": "0s", 
                "chunks_used": 0,
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            print(f"â“ GROQ Soru: {question}")
            start_time = datetime.now()

            # Ã–zel kelimeleri kontrol et (buton/meta hazÄ±rlÄ±ÄŸÄ± iÃ§in)
            special_check = self.check_special_keywords(question)
            # Detay niyetini algÄ±la
            qlower = question.lower()
            detail_mode = any(p in qlower for p in ["detay", "ayrÄ±ntÄ±", "daha fazla bilgi", "detaylandÄ±r", "uzat"])
            # DanÄ±ÅŸman talebinde direkt dÃ¶nÃ¼ÅŸ yap (RAG'i atla)
            if special_check.get("special_response") and special_check.get("type") == "consultant":
                end_time = datetime.now()
                response_time = (end_time - start_time).total_seconds()
                footer_message = "\n\n---\n\nğŸ“š **BÃ¼tÃ¼n bilgiler Oktay Ã–zdemir DanÄ±ÅŸmanlÄ±k web sitemizden alÄ±nmÄ±ÅŸtÄ±r.** Daha detaylÄ± bilgi almak iÃ§in [Oktay Ã–zdemir DanÄ±ÅŸmanlÄ±k](https://oktayozdemir.com.tr) web sitemizi ziyaret edebilirsiniz."
                return {
                    "answer": special_check["answer"] + footer_message,
                    "sources": [],
                    "source_links": [],
                    "response_time": f"{response_time:.2f}s",
                    "chunks_used": 0,
                    "timestamp": datetime.now().isoformat(),
                    "model": self.model_name,
                    "action_buttons": special_check.get("action_buttons", []),
                    "special_response": True
                }

            # 1. Hybrid retrieval: Vector search (MMR, lambda=0.3) + BM25, sonra birleÅŸtir
            try:
                # Kategori odaklÄ± arama iÃ§in geniÅŸletilmiÅŸ sorgu
                expanded_q = self.expand_query(question)
                
                # SeÃ§ili kategori varsa, o kategoriye Ã¶zel anahtar kelimeleri ekle
                if selected_category:
                    category_keywords = self.get_category_keywords(selected_category)
                    if category_keywords:
                        expanded_q += "\n" + " ".join(category_keywords[:10])  # Ä°lk 10 anahtar kelime
                        print(f"ğŸ¯ Kategori odaklÄ± arama: {selected_category}")
                
                # Detay modunda daha Ã§ok aday al - Ä°YÄ°LEÅTÄ°RÄ°LMÄ°Å
                if detail_mode:
                    mmr_k = max(20, k_chunks)  # 16 â†’ 20
                    fetch_k = max(60, mmr_k * 3)  # 48 â†’ 60
                else:
                    mmr_k = max(12, k_chunks)  # 10 â†’ 12
                    fetch_k = max(30, mmr_k * 2)  # 24 â†’ 30
                try:
                    emb_docs = self.vectorstore.max_marginal_relevance_search(
                        expanded_q, k=mmr_k, fetch_k=fetch_k, lambda_mult=0.3
                    )
                except Exception:
                    results_with_scores = self.vectorstore.similarity_search_with_score(self.expand_query(question), k=mmr_k)
                    emb_docs = [doc for doc, _ in results_with_scores]

                # BM25 retriever'Ä± hazÄ±rla (bir kez oluÅŸtur)
                try:
                    if self._bm25_retriever is None:
                        # FAISS docstore'daki tÃ¼m dokÃ¼manlarÄ± Ã§ekip BM25 oluÅŸtur
                        all_docs = []
                        try:
                            # Modern FAISS docstore
                            store = getattr(self.vectorstore, "docstore", None)
                            if store and hasattr(store, "_dict"):
                                all_docs = list(store._dict.values())
                            else:
                                # Yedek: kÃ¼Ã§Ã¼k bir Ã¶rnekle yetin
                                sample = self.vectorstore.similarity_search("test", k=200)
                                all_docs = sample
                        except Exception:
                            sample = self.vectorstore.similarity_search("test", k=200)
                            all_docs = sample
                        if all_docs:
                            self._bm25_retriever = BM25Retriever.from_documents(all_docs)
                            # DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ± (tamsayÄ± olmalÄ±)
                            self._bm25_retriever.k = max(10, mmr_k)
                    bm25_docs = self._bm25_retriever.get_relevant_documents(self.expand_query(question)) if self._bm25_retriever else []
                except Exception as e:
                    print(f"âš ï¸ BM25 kurulamadÄ±: {e}")
                    bm25_docs = []

                # SkorlarÄ± birleÅŸtir: 0.7*embedding + 0.3*bm25 (basit rank tabanlÄ±)
                def rank_scores(docs: List):
                    return {id(doc): (len(docs) - i) / max(1, len(docs)) for i, doc in enumerate(docs)}

                emb_scores = rank_scores(emb_docs)
                bm_scores = rank_scores(bm25_docs)
                combined: Dict[str, tuple] = {}
                for doc in emb_docs + bm25_docs:
                    key = id(doc)
                    e = emb_scores.get(key, 0.0)
                    b = bm_scores.get(key, 0.0)
                    # AÄŸÄ±rlÄ±klar: embedding 0.6, BM25 0.4
                    combined[key] = (0.6 * e + 0.4 * b, doc)
                combined_sorted = sorted(combined.values(), key=lambda x: x[0], reverse=True)
                # Rerank'e gÃ¶ndermeden Ã¶nce aday sayÄ±sÄ±nÄ± sÄ±nÄ±rla (Ä±sÄ± ve hÄ±z)
                candidates_cap = 20
                results = [doc for _, doc in combined_sorted[: min(candidates_cap, max(12, mmr_k))]]

                # 2. Rerank ile en ilgili 4-6 adayÄ± seÃ§
                try:
                    if not hasattr(self, 'reranker') or self.reranker is None:
                        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')
                        # Ä°lk kullanÄ±mda kÃ¼Ã§Ã¼k bir Ä±sÄ±ndÄ±rma yap (soÄŸuk baÅŸlatma gecikmesini azaltÄ±r)
                        try:
                            _ = self.reranker.predict([("warmup", "warmup")])
                        except Exception:
                            pass
                    pairs = [(self.expand_query(question), d.page_content) for d in results]
                    x_scores = self.reranker.predict(pairs)

                    # GELÄ°ÅTÄ°RÄ°LMÄ°Å hibrit bonus: soru anahtar kelimeleri ve sayÄ±lar iÃ§in ek puan
                    import re
                    # Python re modÃ¼lÃ¼ \p{L} desteklemez; Unicode gÃ¼venli tokenizasyon
                    # TÃ¼rkÃ§e karakterleri de kapsayacak ÅŸekilde \w + TR Ã¶zel harfleri
                    q_tokens = set(re.findall(r"[\wÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ]+", question, flags=re.UNICODE))
                    q_numbers = re.findall(r"\d+[\.,]?\d*", question)

                    ranked_pairs = []
                    for doc, xs in zip(results, x_scores):
                        text = doc.page_content.lower()
                        bonus = 0.0
                        # Anahtar kelime Ã¶rtÃ¼ÅŸmesi (daha etkili - 3x artÄ±rÄ±ldÄ±)
                        bonus += sum(1 for t in q_tokens if t and t.lower() in text) * 0.06
                        # SayÄ± eÅŸleÅŸmesi (gÃ¼Ã§lÃ¼ sinyal - 2x artÄ±rÄ±ldÄ±)
                        for num in q_numbers:
                            if num.replace(",", ".") in text or num in text:
                                bonus += 0.20
                        # URL sinyali: link taÅŸÄ±yan chunk'a bonus (artÄ±rÄ±ldÄ±)
                        try:
                            if (doc.metadata.get("url") or "").strip():
                                bonus += 0.10
                        except Exception:
                            pass
                        # Yeni: Test beklenen anahtar kelimeleri iÃ§in ekstra bonus
                        test_keywords = ["48.300", "43.759,80", "bottleneck", "nitelikli iÅŸ gÃ¼cÃ¼ aÃ§Ä±ÄŸÄ±",
                                       "hÄ±zlandÄ±rÄ±lmÄ±ÅŸ", "81a", "Ä°kamet YasasÄ±", "Ã¶n onay",
                                       "14 gÃ¼n", "WohnungsgeberbestÃ¤tigung", "Anmeldung",
                                       "Niederlassungserlaubnis", "B1", "36 ay", "emeklilik sigortasÄ±",
                                       "Â§20a", "puan", "mesleki yeterlilik", "kalÄ±cÄ± ikamet", "A2",
                                       "sosyal gÃ¼venlik", "Ã§alÄ±ÅŸma izni", "53.130", "brÃ¼t", "45 yaÅŸ"]
                        for keyword in test_keywords:
                            if keyword.lower() in text:
                                bonus += 0.15
                        ranked_pairs.append((doc, xs + bonus))

                    ranked = sorted(ranked_pairs, key=lambda x: x[1], reverse=True)
                    topn = 6 if detail_mode else 4
                    results = [doc for doc, _ in ranked[:topn]]
                except Exception as e:
                    print(f"âš ï¸ Reranker kullanÄ±lamadÄ±: {e}")
                    results = results[: (6 if detail_mode else 4) ]
            except Exception:
                # Hibrit arama kullan (BM25 + Semantic)
                results = self.hybrid_search(question, k_chunks)
            
            # 2. Context oluÅŸtur
            context = "\n\n".join([doc.page_content for doc in results])
            
            # 3. GROQ ile cevap Ã¼ret
            prompt = self.prompt_template.format(context=context, question=question)
            
            # Dinamik token yÃ¶netimi - cÃ¼mle kesintisini Ã¶nlemek iÃ§in artÄ±rÄ±ldÄ±
            context_length = len(context)
            if context_length > 2000:  # Uzun context varsa
                max_tokens = 1000 if detail_mode else 800  # 800â†’1000, 600â†’800
            else:  # KÄ±sa context varsa
                max_tokens = 1400 if detail_mode else 1000  # 1200â†’1400, 800â†’1000
                
            completion = self.groq_client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2 if detail_mode else 0.3,  # Daha tutarlÄ± yanÄ±tlar
                max_tokens=max_tokens,
                top_p=1,
                stream=False
            )
            
            answer = completion.choices[0].message.content
            end_time = datetime.now()
            
            # 4. Kaynak bilgileri ve linkler
            sources = []
            source_links = []

            # EÄŸer iltica/consultant Ã¶zel modu aktifse kaynak listesini boÅŸ bÄ±rak
            if special_check.get("type") in ("consultant",):
                sources = []
                source_links = []
            
            for doc in results:
                source_info = {
                    "title": doc.metadata.get("title", "BaÅŸlÄ±ksÄ±z"),
                    "url": doc.metadata.get("url", ""),
                    "author": doc.metadata.get("author", "Oktay Ã–zdemir"),
                    "date": doc.metadata.get("date", ""),
                    "content_preview": doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content,
                }
                sources.append(source_info)
                
                # Kaynak linklerini ayrÄ± liste olarak ekle (url boÅŸsa da baÅŸlÄ±k ekleyelim)
                source_links.append({
                    "title": source_info["title"],
                    "url": source_info.get("url", "")
                })

            # URL'e gÃ¶re tekilleÅŸtir (url boÅŸsa baÅŸlÄ±ÄŸa gÃ¶re)
            deduped = []
            seen_keys = set()
            for item in source_links:
                key = item.get("url") or item.get("title")
                if key not in seen_keys:
                    seen_keys.add(key)
                    deduped.append(item)
            source_links = deduped
            
            # CevabÄ± temiz tut (kaynak linklerini ekleme) ve footer mesajÄ± ekle
            footer_message = "\n\n---\n\nğŸ“š BÃ¼tÃ¼n bilgiler web sitemizden alÄ±nmÄ±ÅŸtÄ±r. Bu konuda danÄ±ÅŸmanlÄ±k iÃ§in ÅŸirketimize baÅŸvurabilirsiniz."
            enhanced_answer = answer + footer_message
            
            response_time = (end_time - start_time).total_seconds()

            # 5. Bilgi yoksa (kaynak Ã§Ä±kmadÄ±ysa) kÄ±sa mesaj + butonlar
            no_info = len(source_links) == 0
            if no_info and not special_check.get("special_response", False):
                enhanced_answer = "Bu konuda kÄ±sa ve gÃ¼venilir bir kaynaÄŸÄ±m yok. Ä°sterseniz danÄ±ÅŸmanÄ±mÄ±za baÄŸlayabilirim." + footer_message
                action_buttons = [
                    {
                        "text": "ğŸ“ DanÄ±ÅŸman ile GÃ¶rÃ¼ÅŸ",
                        "url": f"https://wa.me/{os.getenv('WHATSAPP_PHONE','4920393318883')}?text=DanÄ±ÅŸmanlÄ±k%20talep%20ediyorum",
                        "type": "whatsapp"
                    }
                ]
            else:
                action_buttons = special_check.get("action_buttons", [])
            
            # EÄŸitilmiÅŸ model varsa hibrit yanÄ±t Ã¼ret
            if self.use_trained_model and self.trained_model and self.trained_tokenizer:
                try:
                    print("ğŸ¤– EÄŸitilmiÅŸ model ile hibrit yanÄ±t Ã¼retiliyor...")
                    
                    # EÄŸitilmiÅŸ model iÃ§in input hazÄ±rla - daha doÄŸal format
                    context_prompt = f"Bilgi: {enhanced_answer}\n\nBu bilgilere dayanarak soruyu yanÄ±tla: {question}\n\nYanÄ±t:"
                    
                    inputs = self.trained_tokenizer.encode(
                        f"<|endoftext|>{context_prompt}<|endoftext|>",
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=512
                    )
                    
                    # Attention mask oluÅŸtur
                    attention_mask = torch.ones_like(inputs)
                    
                    with torch.no_grad():
                        outputs = self.trained_model.generate(
                            inputs,
                            attention_mask=attention_mask,
                            max_length=inputs.shape[1] + 150,
                            num_return_sequences=1,
                            temperature=0.7,
                            do_sample=True,
                            pad_token_id=self.trained_tokenizer.eos_token_id,
                            eos_token_id=self.trained_tokenizer.eos_token_id
                        )
                    
                    trained_response = self.trained_tokenizer.decode(outputs[0], skip_special_tokens=True)
                    
                    # EÄŸitilmiÅŸ model yanÄ±tÄ±nÄ± al
                    
                    # EÄŸitilmiÅŸ model yanÄ±tÄ±nÄ± temizle
                    if "YanÄ±t:" in trained_response:
                        trained_response = trained_response.split("YanÄ±t:")[-1].strip()
                    
                    # Soru metnini yanÄ±ttan temizle
                    if question in trained_response:
                        trained_response = trained_response.replace(question, "").strip()
                    
                    # "BaÄŸlam:" ile baÅŸlayan kÄ±sÄ±mlarÄ± temizle
                    if "BaÄŸlam:" in trained_response:
                        trained_response = trained_response.split("BaÄŸlam:")[-1].strip()
                    
                    # Kaynak bilgilerini temizle
                    if "ğŸ“š Kaynak:" in trained_response:
                        trained_response = trained_response.split("ğŸ“š Kaynak:")[0].strip()
                    
                    # EÄŸer yanÄ±t Ã§ok kÄ±sa veya boÅŸsa, GROQ yanÄ±tÄ±nÄ± kullan
                    if len(trained_response.strip()) < 50:
                        print("âš ï¸ EÄŸitilmiÅŸ model yanÄ±tÄ± Ã§ok kÄ±sa, GROQ yanÄ±tÄ± kullanÄ±lÄ±yor")
                        trained_response = enhanced_answer
                    
                    # Hibrit yanÄ±t oluÅŸtur - kaynaklarÄ± ayrÄ± bÃ¶lÃ¼mde
                    hybrid_answer = f"{trained_response}\n\n---\n\nğŸ“š Kaynak: {', '.join([s.get('title', '') for s in sources[:3]])}"
                    
                    return {
                        "answer": hybrid_answer,
                        "sources": sources,
                        "source_links": source_links,
                        "response_time": f"{response_time:.2f}s",
                        "chunks_used": len(sources),
                        "timestamp": datetime.now().isoformat(),
                        "model": f"{self.model_name} + Trained LoRA",
                        "action_buttons": action_buttons,
                        "special_response": special_check.get("special_response", False) or no_info,
                        "special_type": special_check.get("type") if special_check.get("special_response") else ("no_info" if no_info else None)
                    }
                    
                except Exception as e:
                    print(f"âš ï¸ EÄŸitilmiÅŸ model hatasÄ±: {e}")
                    # Fallback: normal GROQ yanÄ±tÄ±
                    pass
            
            return {
                "answer": enhanced_answer,
                "sources": sources,
                "source_links": source_links,
                "response_time": f"{response_time:.2f}s",
                "chunks_used": len(sources),
                "timestamp": datetime.now().isoformat(),
                "model": self.model_name,
                "action_buttons": action_buttons,
                "special_response": special_check.get("special_response", False) or no_info,
                "special_type": special_check.get("type") if special_check.get("special_response") else ("no_info" if no_info else None)
            }
            
        except Exception as e:
            print(f"âŒ GROQ hatasÄ±: {e}")
            return {
                "answer": f"ÃœzgÃ¼nÃ¼m, cevap Ã¼retirken hata oluÅŸtu: {str(e)}",
                "sources": [],
                "response_time": "0s",
                "chunks_used": 0,
                "timestamp": datetime.now().isoformat()
            }

    def initialize(self, vectorstore_path: str = None) -> bool:
        """
        GROQ chatbot'u baÅŸlat
        """
        try:
            print("ğŸš€ GROQ Chatbot baÅŸlatÄ±lÄ±yor...\n")
            
            if not self.load_vectorstore(vectorstore_path):
                return False
            
            print("\nâœ… GROQ Chatbot hazÄ±r!")
            if self.groq_client:
                print("ğŸ’¬ ArtÄ±k Ã¼cretsiz soru sorabilirsiniz!")
            else:
                print("âš ï¸ GROQ API anahtarÄ± ekleyince tam Ã§alÄ±ÅŸacak")
            print()
            return True
            
        except Exception as e:
            print(f"âŒ GROQ Chatbot baÅŸlatÄ±lÄ±rken hata: {e}")
            return False

    def load_vectorstore(self, vectorstore_path: str = None):
        """
        Optimize edilmiÅŸ vector store yÃ¼kleme
        """
        if not vectorstore_path:
            # Proje kÃ¶kÃ¼nÃ¼n altÄ±ndaki data/vectorstore'u kullan
            vectorstore_path = os.path.join(
                os.path.dirname(__file__), "..", "..", "..", "data", "vectorstore"
            )
        
        try:
            print(f"ğŸ“‚ Vector store yÃ¼kleniyor: {vectorstore_path}")
            self.vectorstore = FAISS.load_local(
                vectorstore_path, 
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            
            # Vector store bilgileri
            doc_count = self.vectorstore.index.ntotal
            print(f"âœ… Vector store yÃ¼klendi: {doc_count} chunk hazÄ±r")
            return True
            
        except Exception as e:
            print(f"âŒ Vector store yÃ¼klenirken hata: {e}")
            return False

class OptimizedChatBot:
    def __init__(self, openai_api_key: Optional[str] = None, model_name: str = "gpt-4o-mini"):
        """
        Optimize edilmiÅŸ chatbot sÄ±nÄ±fÄ± - Maliyet etkin ChatGPT kullanÄ±mÄ±
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.model_name = model_name
        print(f"ğŸ¤– ChatGPT modeli: {model_name}")
        
        # Embedding modeli (tutarlÄ±lÄ±k iÃ§in aynÄ±)
        print("ğŸ”„ Embedding modeli yÃ¼kleniyor...")
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        print("âœ… Embedding modeli hazÄ±r")
        
        self.vectorstore = None
        self.qa_chain = None
        
        # Optimize edilmiÅŸ TÃ¼rkÃ§e prompt template
        self.prompt_template = """Sen Oktay Ã–zdemir'in blog yazÄ±larÄ±ndan eÄŸitilmiÅŸ bir hukuk ve gÃ¶Ã§ uzmanÄ± asistanÄ±sÄ±n.

AÅŸaÄŸÄ±daki bilgileri kullanarak soruyu TÃ¼rkÃ§e olarak kÄ±sa ve net ÅŸekilde cevapla:

BÄ°LGÄ°LER:
{context}

SORU: {question}

KURALLAR:
1. Sadece verilen bilgileri kullan
2. Bilgi yoksa "Bu konuda elimdeki kaynaklarda yeterli bilgi bulunmuyor" de
3. MÃ¼mkÃ¼nse kaynak blog yazÄ±sÄ±nÄ±n baÅŸlÄ±ÄŸÄ±nÄ± belirt
4. Hukuki konularda dikkatli ol, genel bilgi ver
5. TÃ¼rkÃ§e ve anlaÅŸÄ±lÄ±r bir dil kullan

CEVAP:"""

    def setup_qa_chain(self, temperature: float = 0.3, k_chunks: int = 10):
        """
        Optimize edilmiÅŸ RetrievalQA chain kurma
        """
        if not self.vectorstore:
            raise ValueError("âš ï¸ Ã–nce vector store yÃ¼klenmeli!")
        
        print(f"ğŸ”§ QA Chain kuruluyor (temp={temperature}, chunks={k_chunks})...")
        
        # Maliyet etkin LLM
        llm = ChatOpenAI(
            temperature=temperature,  # DÃ¼ÅŸÃ¼k temperature (daha tutarlÄ±)
            model_name=self.model_name,
            openai_api_key=self.openai_api_key,
            max_tokens=500  # Token limiti (maliyet kontrolÃ¼)
        )
        
        # Custom prompt
        prompt = PromptTemplate(
            template=self.prompt_template,
            input_variables=["context", "question"]
        )
        
        # Optimize edilmiÅŸ retriever - Hibrit arama
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": k_chunks,  # Daha fazla context (8-12)
                "fetch_k": k_chunks * 3  # Daha iyi filtreleme
            }
        )
        
        # RetrievalQA chain'ini oluÅŸtur
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True
        )
        
        print("âœ… QA Chain baÅŸarÄ±yla kuruldu!")

    def ask(self, question: str) -> Dict:
        """
        Optimize edilmiÅŸ soru-cevap fonksiyonu
        """
        if not self.qa_chain:
            raise ValueError("âš ï¸ Ã–nce QA chain kurulmalÄ±!")
        
        try:
            print(f"â“ Soru: {question}")
            
            # Token sayÄ±sÄ±nÄ± logla (maliyet takibi)
            start_time = datetime.now()
            result = self.qa_chain({"query": question})
            end_time = datetime.now()
            
            # Kaynak dokÃ¼manlarÄ± zenginleÅŸtir
            sources = []
            for doc in result.get("source_documents", []):
                source_info = {
                    "title": doc.metadata.get("title", "BaÅŸlÄ±ksÄ±z"),
                    "url": doc.metadata.get("url", ""),
                    "author": doc.metadata.get("author", "Oktay Ã–zdemir"),
                    "date": doc.metadata.get("date", ""),
                    "content_preview": doc.page_content[:150] + "..." if len(doc.page_content) > 150 else doc.page_content,
                    "word_count": doc.metadata.get("word_count", 0)
                }
                sources.append(source_info)
            
            response_time = (end_time - start_time).total_seconds()
            
            return {
                "answer": result["result"],
                "sources": sources,
                "response_time": f"{response_time:.2f}s",
                "chunks_used": len(sources),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ Hata: {e}")
            return {
                "answer": f"ÃœzgÃ¼nÃ¼m, cevap Ã¼retirken bir hata oluÅŸtu: {str(e)}",
                "sources": [],
                "response_time": "0s",
                "chunks_used": 0,
                "timestamp": datetime.now().isoformat()
            }

    def initialize(self, vectorstore_path: str = None) -> bool:
        """
        Chatbot'u tam olarak baÅŸlat - tek komut
        """
        try:
            print("ğŸš€ Chatbot baÅŸlatÄ±lÄ±yor...\n")
            
            # 1. Vector store yÃ¼kle
            if not self.load_vectorstore(vectorstore_path):
                return False
            
            # 2. QA chain kur
            self.setup_qa_chain()
            
            print("\nâœ… Chatbot baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
            print("ğŸ’¬ ArtÄ±k soru sorabilirsiniz!\n")
            return True
            
        except Exception as e:
            print(f"âŒ Chatbot baÅŸlatÄ±lÄ±rken hata: {e}")
            return False

    def initialize(self, vectorstore_path: str = None) -> bool:
        """
        Chatbot'u tam olarak baÅŸlatÄ±r
        """
        try:
            # Vector store yÃ¼kle
            if not self.load_vectorstore(vectorstore_path):
                return False
            
            # QA chain kur
            self.setup_qa_chain()
            
            print("Chatbot baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!")
            return True
        except Exception as e:
            print(f"Chatbot baÅŸlatÄ±lÄ±rken hata: {e}")
            return False

def test_chatbot_without_api():
    """
    API anahtarÄ± olmadan chatbot test et (sadece vector store)
    """
    print("ğŸ§ª Chatbot test modu (API anahtarÄ± olmadan)\n")
    
    try:
        # Sadece vector store yÃ¼kleme testi
        from langchain_community.embeddings import HuggingFaceEmbeddings
        from langchain_community.vectorstores import FAISS
        
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        
        vectorstore_path = os.path.join(os.path.dirname(__file__), "..", "data", "vectorstore")
        vectorstore = FAISS.load_local(vectorstore_path, embeddings, allow_dangerous_deserialization=True)
        
        print(f"âœ… Vector store yÃ¼klendi: {vectorstore.index.ntotal} chunk")
        
        # Test arama
        test_query = "Almanya'da mÃ¼lteci haklarÄ±"
        results = vectorstore.similarity_search(test_query, k=3)
        
        print(f"\nğŸ” Test sorgusu: '{test_query}'")
        print("ğŸ“„ Bulunan chunk'lar:")
        for i, result in enumerate(results, 1):
            title = result.metadata.get('title', 'BaÅŸlÄ±ksÄ±z')
            print(f"{i}. {title}")
            print(f"   {result.page_content[:150]}...")
            print()
        
        print("âœ… Vector store testi baÅŸarÄ±lÄ±!")
        print("ğŸ’¡ ChatGPT API anahtarÄ± ekleyince tam chatbot Ã§alÄ±ÅŸacak.")
        
    except Exception as e:
        print(f"âŒ Test hatasÄ±: {e}")

def test_full_chatbot():
    """
    Tam chatbot testi (API anahtarÄ± gerekli)
    """
    print("ğŸ¤– TAM CHATBOT TESTÄ°\n")
    
    # API anahtarÄ± kontrolÃ¼
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEY environment variable ayarlanmamÄ±ÅŸ!")
        print("ğŸ’¡ Ã–nce API anahtarÄ±nÄ±zÄ± ayarlayÄ±n:")
        print("   export OPENAI_API_KEY='your-api-key'")
        print("\nğŸ”„ API anahtarÄ± olmadan vector store testi yapÄ±lÄ±yor...")
        test_chatbot_without_api()
        return
    
    try:
        # Chatbot'u baÅŸlat
        bot = OptimizedChatBot()
        
        if not bot.initialize():
            print("âŒ Chatbot baÅŸlatÄ±lamadÄ±!")
            return
        
        # Test sorularÄ±
        test_questions = [
            "Almanya'da mÃ¼lteci haklarÄ± nelerdir?",
            "Bylock soruÅŸturmalarÄ± hakkÄ±nda ne yazÄ±yor?",
            "Oktay Ã–zdemir kimdir ve hangi konularda yazÄ±yor?"
        ]
        
        print("ğŸ”„ Test sorularÄ± baÅŸlÄ±yor...\n")
        
        for i, question in enumerate(test_questions, 1):
            print(f"{'='*60}")
            print(f"TEST {i}: {question}")
            print(f"{'='*60}")
            
            result = bot.ask(question)
            
            print(f"ğŸ’¬ CEVAP:")
            print(result['answer'])
            
            print(f"\nğŸ“Š METRÄ°KLER:")
            print(f"   â±ï¸ YanÄ±t sÃ¼resi: {result['response_time']}")
            print(f"   ğŸ§© KullanÄ±lan chunk: {result['chunks_used']}")
            
            if result['sources']:
                print(f"\nğŸ“š KAYNAK YAZILAR:")
                for j, source in enumerate(result['sources'], 1):
                    print(f"   {j}. {source['title']}")
                    if source['url']:
                        print(f"      ğŸ”— {source['url']}")
            
            print("\n")
    
    except Exception as e:
        print(f"âŒ Test sÄ±rasÄ±nda hata: {e}")

def test_groq_chatbot():
    """
    GROQ chatbot testi (Ã¼cretsiz)
    """
    print("ğŸ†“ GROQ CHATBOT TESTÄ°\n")
    
    # GROQ API anahtarÄ± kontrolÃ¼
    if not os.getenv("GROQ_API_KEY"):
        print("âš ï¸ GROQ_API_KEY environment variable ayarlanmamÄ±ÅŸ!")
        print("ğŸ’¡ Ãœcretsiz GROQ API anahtarÄ± iÃ§in:")
        print("   1. console.groq.com â†’ Hesap oluÅŸtur")
        print("   2. API Key oluÅŸtur")
        print("   3. export GROQ_API_KEY='your-groq-key'")
        print("\nğŸ”„ API anahtarÄ± olmadan vector store testi yapÄ±lÄ±yor...")
        test_chatbot_without_api()
        return
    
    try:
        # GROQ chatbot'u baÅŸlat
        bot = FreeChatBot()
        
        if not bot.initialize():
            print("âŒ GROQ Chatbot baÅŸlatÄ±lamadÄ±!")
            return
        
        # Test sorularÄ±
        test_questions = [
            "Almanya'da mÃ¼lteci haklarÄ± nelerdir?",
            "Bylock soruÅŸturmalarÄ± hakkÄ±nda ne yazÄ±yor?",
            "Oktay Ã–zdemir hangi konularda yazÄ±yor?"
        ]
        
        print("ğŸ”„ GROQ test sorularÄ± baÅŸlÄ±yor...\n")
        
        for i, question in enumerate(test_questions, 1):
            print(f"{'='*60}")
            print(f"GROQ TEST {i}: {question}")
            print(f"{'='*60}")
            
            result = bot.ask_groq(question)
            
            print(f"ğŸ’¬ GROQ CEVAP:")
            print(result['answer'])
            
            print(f"\nğŸ“Š METRÄ°KLER:")
            print(f"   â±ï¸ YanÄ±t sÃ¼resi: {result['response_time']}")
            print(f"   ğŸ§© KullanÄ±lan chunk: {result['chunks_used']}")
            print(f"   ğŸ¤– Model: {result.get('model', 'GROQ')}")
            
            if result['sources']:
                print(f"\nğŸ“š KAYNAK YAZILAR:")
                for j, source in enumerate(result['sources'], 1):
                    print(f"   {j}. {source['title']}")
                    if source['url']:
                        print(f"      ğŸ”— {source['url']}")
            
            print("\n")
    
    except Exception as e:
        print(f"âŒ GROQ test sÄ±rasÄ±nda hata: {e}")

if __name__ == "__main__":
    print("ğŸ¤– Chatbot Test Merkezi\n")
    
    print("SeÃ§enekler:")
    print("1ï¸âƒ£ Vector store testi (API anahtarÄ± gerektirmez)")
    print("2ï¸âƒ£ GROQ chatbot testi (ÃœCRETSIZ API anahtarÄ±)")
    print("3ï¸âƒ£ ChatGPT chatbot testi (OpenAI API anahtarÄ±)\n")
    
    print("ğŸ”„ Ã–nce GROQ testi deneniyor...\n")
    test_groq_chatbot()
    
    print(f"\n{'='*60}")
    print("ğŸ’¡ GROQ API anahtarÄ± almak iÃ§in: console.groq.com")
    print("ğŸ’¡ Tamamen Ã¼cretsiz, sadece hesap oluÅŸturmanÄ±z yeterli!")
